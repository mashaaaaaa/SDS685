# -*- coding: utf-8 -*-
"""S&DS 685 Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XFVCWmJ2J3PsjNnZj_DEyBi3JVjLVE7b
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import BayesianRidge
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_absolute_error

# Load the MovieLens 100K dataset
ratings = pd.read_csv('u.data', sep='\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])
movies = pd.read_csv('u.item', sep='|', encoding='latin-1', names=['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])
users = pd.read_csv('u.user', sep='|', names=['user_id', 'age', 'gender', 'occupation', 'zip_code'])

# Merge the dataset
data = pd.merge(pd.merge(ratings, users, on='user_id'), movies, on='movie_id')

# One-hot encode categorical features
encoder = OneHotEncoder()
encoded_occupations = encoder.fit_transform(data[['occupation']]).toarray()
encoded_genres = data.iloc[:, 24:].to_numpy()

# Normalize continuous features
scaler = StandardScaler()
normalized_age = scaler.fit_transform(data[['age']])
normalized_release_year = scaler.fit_transform(pd.to_datetime(data['release_date']).dt.year.to_frame())

# Create the feature matrix
X = np.hstack((data[['user_id', 'movie_id']].to_numpy(), encoded_occupations, normalized_age, encoded_genres, normalized_release_year))
imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)
y = data['rating'].to_numpy()

class ThompsonSampling:
    def __init__(self, n_features):
        self.n_features = n_features
        self.model = BayesianRidge()

    def fit(self, X, y):
        self.model.fit(X, y)

    def predict(self, X):
        return self.model.predict(X)

    def update(self, X, y):
        self.model.fit(X, y)

np.random.seed(42)
n_users = data['user_id'].nunique()
n_movies = data['movie_id'].nunique()

thompson_sampling = ThompsonSampling(n_features=X.shape[1])

# Fit the model with a small subset of the data
sample_size = 100
random_indices = np.random.choice(np.arange(X.shape[0]), size=sample_size, replace=False)
thompson_sampling.fit(X[random_indices], y[random_indices])

cumulative_regret = 0
n_recommendations = 0
total_reward = 0
optimal_reward = 0

n_relevant_recommendations = 0
n_total_recommendations = 0

mae_sum = 0
n_predictions = 0
K=5

for user_id in range(1, n_users + 1):
    user_data = data[data['user_id'] == user_id]

    if not user_data.empty:
        X_user = X[user_data.index]
        y_user = y[user_data.index]

        predictions = thompson_sampling.predict(X_user)
        recommended_movie_idx = np.argmax(predictions)
        actual_rating = y_user[recommended_movie_idx]

        # Precision@K
        top_K_movies_idx = np.argsort(predictions)[-K:]
        relevant_recommendations = np.sum(y_user[top_K_movies_idx] >= 4)  # Assuming a rating of 4 or higher is relevant
        n_relevant_recommendations += relevant_recommendations
        n_total_recommendations += K

        # Mean Absolute Error
        mae_sum += mean_absolute_error(y_user, predictions)
        n_predictions += len(predictions)

        optimal_rating = np.max(y_user)
        regret = optimal_rating - actual_rating

        cumulative_regret += regret
        total_reward += actual_rating
        optimal_reward += optimal_rating
        n_recommendations += 1

        # Update the model
        thompson_sampling.update(X_user[recommended_movie_idx].reshape(1, -1), np.array([actual_rating]))

# Evaluation Metrics
average_regret = cumulative_regret / n_recommendations
average_reward = total_reward / n_recommendations
optimal_average_reward = optimal_reward / n_recommendations
precision_at_K = n_relevant_recommendations / n_total_recommendations
mean_abs_error = mae_sum / n_predictions

print(f"Average Regret: {average_regret}")
print(f"Average Reward: {average_reward}")
print(f"Optimal Average Reward: {optimal_average_reward}")
print(f"Precision@{K}: {precision_at_K}")
print(f"Mean Absolute Error: {mean_abs_error}")

"""# New Section"""